# ğŸ¯ GOAP System - Complete Analysis & Documentation

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [What is GOAP?](#what-is-goap)
3. [System Architecture Overview](#system-architecture-overview)
4. [Core Components Deep Dive](#core-components-deep-dive)
5. [How Classes Connect](#how-classes-connect)
6. [The Planning Algorithm Explained](#the-planning-algorithm-explained)
7. [Practical Examples & Scenarios](#practical-examples--scenarios)
8. [Code Flow Diagrams](#code-flow-diagrams)
9. [Extending the System](#extending-the-system)

---

## Executive Summary

This is a **Goal-Oriented Action Planning (GOAP)** AI system for Unity that enables NPCs to make intelligent, dynamic decisions. Unlike traditional Finite State Machines (FSMs) or Behavior Trees, GOAP agents:

- âœ… **Think for themselves** - They create their own plans to achieve goals
- âœ… **Adapt dynamically** - They replan when situations change
- âœ… **Scale easily** - New actions/goals can be added without breaking existing code
- âœ… **Create emergent behavior** - Complex behaviors emerge from simple action combinations

**Current Implementation Status**: Basic framework with wandering/idling behaviors. The system is designed to be extended with combat, resource gathering, social interactions, etc.

---

## What is GOAP?

### The Core Philosophy

**Traditional AI (FSMs/Behavior Trees)**:

- You explicitly tell the NPC: "If enemy is near AND you have weapon THEN attack"
- Every combination must be manually programmed
- Gets exponentially complex as you add more states

**GOAP AI**:

- You give the NPC: Goals ("kill enemy"), Actions ("shoot", "find weapon"), and the current World State
- The NPC figures out: "I want to kill enemy â†’ I need weapon â†’ I should find weapon first"
- Plans are generated automatically using graph search algorithms

### Key Terminology

| Term             | Definition                                       | Example                              |
| ---------------- | ------------------------------------------------ | ------------------------------------ |
| **Belief**       | A fact the agent knows about the world           | "Player is nearby" = true            |
| **Precondition** | What must be true to perform an action           | "Has weapon" required to "Shoot"     |
| **Effect**       | What becomes true after an action completes      | "Shoot" makes "Enemy is dead" = true |
| **Goal**         | A desired world state the agent wants to achieve | "Enemy is dead" = true               |
| **Action**       | Something the agent can do to change the world   | "Shoot", "Reload", "Find Cover"      |
| **Plan**         | An ordered sequence of actions to achieve a goal | [Find Weapon â†’ Load Weapon â†’ Shoot]  |

---

## System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GOAP AGENT                           â”‚
â”‚  (GoapAgent.cs - The "Brain" of the NPC)                    â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   BELIEFS    â”‚  â”‚   ACTIONS    â”‚  â”‚    GOALS     â”‚       â”‚
â”‚  â”‚ (World State)â”‚  â”‚ (What I can  â”‚  â”‚ (What I want)â”‚       â”‚
â”‚  â”‚ What I know  â”‚  â”‚     do)      â”‚  â”‚              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                  â”‚                  â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                            â–¼                                â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                   â”‚  GOAP PLANNER  â”‚                        â”‚
â”‚                   â”‚ (GoapPlanner)  â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                            â”‚                                â”‚
â”‚                            â–¼                                â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                   â”‚  ACTION PLAN   â”‚                        â”‚
â”‚                   â”‚  (Stack of     â”‚                        â”‚
â”‚                   â”‚   Actions)     â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                            â”‚                                â”‚
â”‚                            â–¼                                â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                   â”‚   STRATEGIES   â”‚                        â”‚
â”‚                   â”‚ (How actions   â”‚                        â”‚
â”‚                   â”‚  are executed) â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SENSORS    â”‚          â”‚  UTILITIES   â”‚
         â”‚ (Perception) â”‚          â”‚ (Helpers)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Components Deep Dive

### 1. ğŸ§  **AgentBelief** (`Belief.cs`)

**Purpose**: Represents a single fact about the world that the agent believes to be true or false.

**Structure**:

```csharp
AgentBelief
â”œâ”€â”€ Name: string (identifier like "PlayerNearby")
â”œâ”€â”€ Condition: Func<bool> (lambda that checks if belief is true)
â””â”€â”€ Location: Func<Vector3> (optional - where the belief is located)
```

**How it works**:

- Each belief is essentially a boolean flag with a name
- The `condition` function is called to check if the belief is currently true
- Optionally stores a location (useful for "Food is at X position")

**Example**:

```csharp
// A belief that's true when the agent is idle (not moving)
factory.AddBelief("AgentIdle", () => !navMeshAgent.hasPath);

// A belief with a location (player's position when in sensor range)
factory.AddSensorBelief("PlayerNearby", playerSensor);
```

**Builder Pattern**: Uses a fluent builder pattern for clean construction:

```csharp
new AgentBelief.Builder("PlayerNearby")
    .WithCondition(() => sensor.IsTargetInRange)
    .WithLocation(() => sensor.TargetPosition)
    .Build()
```

---

### 2. ğŸ¬ **AgentAction** (`Actions.cs`)

**Purpose**: Represents something the agent can DO. Actions are the building blocks of plans.

**Structure**:

```csharp
AgentAction
â”œâ”€â”€ Name: string (e.g., "Wander Around")
â”œâ”€â”€ Cost: float (default 1, lower = more preferred)
â”œâ”€â”€ Preconditions: HashSet<AgentBelief> (what must be true to start)
â”œâ”€â”€ Effects: HashSet<AgentBelief> (what becomes true after completing)
â””â”€â”€ Strategy: IActionStrategy (HOW the action is executed)
```

**The Action Lifecycle**:

1. **Can Start?** â†’ Check if all preconditions are met
2. **Start()** â†’ Initialize the strategy (e.g., calculate wander position)
3. **Update()** â†’ Execute strategy each frame until complete
4. **Complete?** â†’ Strategy determines when action is done
5. **Stop()** â†’ Clean up

**Example Action**:

```csharp
new AgentAction.Builder("Wander Around")
    .WithCost(1)  // Neutral cost
    .WithStrategy(new WanderStrategy(navMeshAgent, 5))  // HOW to wander
    .AddPrecondition(beliefs["AgentIdle"])  // Must be idle to start wandering
    .AddEffect(beliefs["AgentMoving"])  // After wandering, agent is moving
    .Build()
```

**Key Insight**: Actions are **modular** and **reusable**. An action doesn't care about goals - it just knows:

- "I need X to start" (preconditions)
- "I will make Y true" (effects)
- "Here's how I execute" (strategy)

---

### 3. ğŸ¯ **AgentGoal** (`Goals.cs`)

**Purpose**: Represents a desired world state the agent wants to achieve.

**Structure**:

```csharp
AgentGoal
â”œâ”€â”€ Name: string (e.g., "Chill Out")
â”œâ”€â”€ Priority: float (higher = more important)
â””â”€â”€ DesiredEffects: HashSet<AgentBelief> (beliefs that should be true)
```

**How Priority Works**:

- Goals are evaluated in descending priority order
- If a higher-priority goal becomes achievable, the current plan is abandoned
- The `mostRecentGoal` gets a slight penalty (priority - 0.01) to avoid flip-flopping

**Example**:

```csharp
new AgentGoal.Builder("Survive")
    .WithPriority(10)  // VERY important
    .WithDesiredEffects(beliefs["HealthFull"])
    .Build()

new AgentGoal.Builder("Chill Out")
    .WithPriority(1)  // Low priority fallback
    .WithDesiredEffects(beliefs["Nothing"])  // Always false = always achievable
    .Build()
```

---

### 4. ğŸ§® **GoapPlanner** (`GoapPlanner.cs`)

**Purpose**: The "genius" of the system. Uses backward-chaining graph search to find action sequences.

**The Planning Algorithm** (Simplified):

```
1. Sort goals by priority (highest first)
2. For each goal:
   a. Create a goal node with desired effects
   b. Find actions whose effects contribute to the goal
   c. If action's preconditions aren't met, make them new subgoals
   d. Recursively solve subgoals
   e. Build a tree of possible action sequences
   f. Return the cheapest path (lowest total cost)
3. If no plan found for any goal, return null
```

**Backward Chaining Example**:

```
Goal: "Has Food" = true
Current State: "Has Food" = false, "At Kitchen" = false

Planner thinks backward:
1. What makes "Has Food" true? â†’ "Cook Meal" action
2. Can I "Cook Meal"? â†’ Precondition: "At Kitchen" = true
3. How do I get to kitchen? â†’ "Go To Kitchen" action
4. Can I go to kitchen? â†’ No preconditions! âœ…

Final Plan: [Go To Kitchen] â†’ [Cook Meal]
```

**Graph Search Details**:

- Uses a **recursive depth-first** approach
- Builds a tree of `Node` objects (each represents a world state)
- Each node tracks:
  - Parent node
  - Action that led here
  - Required effects still needed
  - Cumulative cost
  - Child nodes (leaves)

---

### 5. ğŸ¤– **GoapAgent** (`GoapAgent.cs`)

**Purpose**: The main MonoBehaviour that brings everything together. This is the "brain" attached to NPCs.

**Initialization Flow** (in `Start()`):

```
1. SetupTimers()    â†’ Create stat update timers
2. SetupBeliefs()   â†’ Define what the agent knows
3. SetupActions()   â†’ Define what the agent can do
4. SetupGoals()     â†’ Define what the agent wants
```

**Update Loop Logic**:

```csharp
void Update() {
    // 1. Update stats (health, stamina)
    statsTimer.Tick(Time.deltaTime);

    // 2. Update animations based on movement
    animations.SetSpeed(navMeshAgent.velocity.magnitude);

    // 3. Do we need a new plan?
    if (currentAction == null) {
        CalculatePlan();  // Ask planner for a new plan

        if (plan found) {
            currentGoal = plan.Goal;
            currentAction = plan.Actions.Pop();  // Get first action
            currentAction.Start();
        }
    }

    // 4. Execute current action
    if (currentAction != null) {
        currentAction.Update(Time.deltaTime);

        if (currentAction.Complete) {
            currentAction.Stop();

            if (no more actions in plan) {
                // Plan complete! Reset for next frame
                currentGoal = null;
                currentAction = null;
            }
        }
    }
}
```

**Planning Strategy**:

- If no goal â†’ check ALL goals
- If current goal exists â†’ only check **higher priority** goals
- This allows interrupting low-priority tasks for emergencies

---

### 6. ğŸ‘ï¸ **Sensor** (`Sensor.cs`)

**Purpose**: Gives the agent perception of the world using Unity's physics system.

**How it works**:

```
1. SphereCollider (trigger) defines detection radius
2. OnTriggerEnter â†’ Player walks into range â†’ Update beliefs
3. OnTriggerExit â†’ Player leaves â†’ Update beliefs
4. Timer-based position updates (prevents excessive updates)
5. OnTargetChanged event â†’ Notifies agent when target changes
```

**Integration with Beliefs**:

```csharp
// In GoapAgent:
factory.AddSensorBelief("PlayerNearby", chaseSensor);

// This creates a belief that:
// - Is TRUE when chaseSensor.IsTargetInRange
// - Has LOCATION at chaseSensor.TargetPosition
```

**Event System**:

```csharp
// When sensor detects change:
OnTargetChanged?.Invoke();

// GoapAgent listens:
chaseSensor.OnTargetChanged += HandleTargetChanged;

// Handler forces replanning:
void HandleTargetChanged() {
    currentAction = null;  // Force recalculation
    currentGoal = null;
}
```

---

### 7. âš™ï¸ **Strategies** (`Strategies.cs`)

**Purpose**: Defines HOW actions are executed. Separates planning from execution.

**IActionStrategy Interface**:

```csharp
interface IActionStrategy {
    bool CanPerform { get; }  // Is action executable right now?
    bool Complete { get; }     // Has action finished?
    void Start();              // Initialize
    void Update(float dt);     // Execute each frame
    void Stop();               // Cleanup
}
```

**Built-in Strategies**:

#### IdleStrategy

```csharp
public class IdleStrategy : IActionStrategy {
    CountdownTimer timer;

    // Wait for X seconds, then mark complete
    public void Start() => timer.Start();
    public void Update(float dt) => timer.Tick(dt);
    public bool Complete => timer.IsFinished;
}
```

#### WanderStrategy

```csharp
public class WanderStrategy : IActionStrategy {
    NavMeshAgent agent;
    float wanderRadius;

    public void Start() {
        // Find random point on NavMesh within radius
        Vector3 randomDir = Random.insideUnitSphere * wanderRadius;
        NavMeshHit hit;
        if (NavMesh.SamplePosition(agent.position + randomDir, out hit, radius, 1)) {
            agent.SetDestination(hit.position);
        }
    }

    public bool Complete => agent.remainingDistance <= 2f && !agent.pathPending;
}
```

---

### 8. ğŸ¬ **AnimationController** (`AnimationController.cs`)

**Purpose**: Abstract base class for handling Unity Animator interactions.

**Design Pattern**: Template Method Pattern

- Base class handles common logic (timers, crossfading)
- Derived classes define specific animation clip hashes

**How it works**:

```csharp
// Set locomotion blend tree speed based on velocity
SetSpeed(navMeshAgent.velocity.magnitude);

// Play attack animation for its duration, then return to locomotion
Attack() â†’
    1. Get animation length
    2. Start timer
    3. Crossfade to attack clip
    4. When timer ends â†’ Crossfade back to locomotion
```

---

### 9. â±ï¸ **Timer** (`Timer.cs`)

**Purpose**: Reusable timer system with event callbacks.

**CountdownTimer**:

```csharp
CountdownTimer timer = new CountdownTimer(5f);
timer.OnTimerStart += () => Debug.Log("Started!");
timer.OnTimerStop += () => Debug.Log("Finished!");
timer.Start();

void Update() {
    timer.Tick(Time.deltaTime);  // Counts down to 0
}
```

**Common Use Cases**:

- Stat regeneration (`statsTimer` in GoapAgent)
- Sensor update intervals (`timer` in Sensor)
- Animation duration (`timer` in AnimationController)
- Idle action duration (`timer` in IdleStrategy)

---

## How Classes Connect

### ğŸ”— Dependency Graph

```
GoapAgent (Main Controller)
    â”œâ”€â”€ Requires: NavMeshAgent, AnimationController, Rigidbody
    â”œâ”€â”€ Uses: GoapPlanner (to create plans)
    â”œâ”€â”€ Contains: BeliefFactory (to build beliefs)
    â”œâ”€â”€ Manages:
    â”‚   â”œâ”€â”€ Dictionary<string, AgentBelief> beliefs
    â”‚   â”œâ”€â”€ HashSet<AgentAction> actions
    â”‚   â”œâ”€â”€ HashSet<AgentGoal> goals
    â”‚   â””â”€â”€ ActionPlan currentPlan
    â””â”€â”€ Subscribes: Sensor.OnTargetChanged

GoapPlanner
    â”œâ”€â”€ Input: GoapAgent, HashSet<AgentGoal>, (optional) mostRecentGoal
    â”œâ”€â”€ Output: ActionPlan (or null)
    â””â”€â”€ Internal: Node tree for graph search

AgentAction
    â”œâ”€â”€ References: AgentBelief (preconditions & effects)
    â””â”€â”€ Contains: IActionStrategy (execution logic)

AgentGoal
    â””â”€â”€ References: AgentBelief (desired effects)

AgentBelief
    â”œâ”€â”€ Contains: Func<bool> condition
    â””â”€â”€ Optional: Func<Vector3> location

BeliefFactory
    â”œâ”€â”€ Input: GoapAgent, Dictionary<string, AgentBelief>
    â””â”€â”€ Creates: AgentBelief instances

Sensor
    â”œâ”€â”€ Requires: SphereCollider
    â”œâ”€â”€ Uses: CountdownTimer
    â””â”€â”€ Provides: OnTargetChanged event, TargetPosition, IsTargetInRange

Strategies (IdleStrategy, WanderStrategy)
    â”œâ”€â”€ Uses: CountdownTimer (Idle)
    â””â”€â”€ Uses: NavMeshAgent (Wander)

AnimationController
    â”œâ”€â”€ Uses: Animator, CountdownTimer
    â””â”€â”€ Abstract: Must be inherited with specific clip definitions
```

### ğŸ”„ Data Flow

```
FRAME N:
1. GoapAgent.Update() executes
2. statsTimer.Tick() â†’ Updates health/stamina
3. No currentAction â†’ CalculatePlan()
   â”œâ”€â”€ GoapPlanner.Plan(agent, goals, lastGoal)
   â”‚   â”œâ”€â”€ Reads agent.beliefs (current world state)
   â”‚   â”œâ”€â”€ Reads agent.actions (available actions)
   â”‚   â”œâ”€â”€ Reads goals (sorted by priority)
   â”‚   â””â”€â”€ Returns ActionPlan with Stack<AgentAction>
   â””â”€â”€ Pop first action â†’ currentAction.Start()
       â””â”€â”€ strategy.Start() initializes

FRAME N+1 to N+X:
4. currentAction.Update(deltaTime)
   â”œâ”€â”€ strategy.Update(deltaTime) executes
   â””â”€â”€ Checks strategy.Complete
       â”œâ”€â”€ If complete â†’ Apply action.Effects
       â””â”€â”€ Pop next action or mark plan complete

FRAME N+X+1:
5. Plan complete â†’ currentAction = null â†’ Loop to step 3

INTERRUPT (Player enters sensor range):
* Sensor.OnTriggerEnter() â†’ UpdateTargetPosition()
* OnTargetChanged.Invoke()
* GoapAgent.HandleTargetChanged() â†’ currentAction = null, currentGoal = null
* Next frame â†’ Replanning occurs with new world state
```

---

## The Planning Algorithm Explained

### Step-by-Step Walkthrough

Let's trace through a realistic scenario:

**Setup**:

```
Agent Stats:
- Health: 20 (low!)
- Stamina: 100

Beliefs:
- "AgentIdle": true (not moving)
- "AgentMoving": false
- "AtFoodShack": false (10 units away)
- "HealthLow": true (< 30)

Actions:
1. "Relax" (cost: 1)
   - Preconditions: None
   - Effects: "Nothing" (always false)
   - Strategy: Idle for 5 seconds

2. "Wander" (cost: 1)
   - Preconditions: "AgentIdle"
   - Effects: "AgentMoving"
   - Strategy: Walk to random point

3. "Go To Food Shack" (cost: 2)
   - Preconditions: "AgentIdle"
   - Effects: "AtFoodShack", "AgentMoving"
   - Strategy: Navigate to food shack

4. "Eat Food" (cost: 1)
   - Preconditions: "AtFoodShack"
   - Effects: "HealthLow" becomes false
   - Strategy: Idle for 3 seconds

Goals:
- "Stay Healthy" (priority: 10)
  - Desired: "HealthLow" = false
- "Wander" (priority: 1)
  - Desired: "AgentMoving" = true
```

### Planning Execution

**Phase 1: Goal Selection**

```
1. Sort goals by priority:
   [Stay Healthy (10), Wander (1)]

2. Filter goals where desired effects aren't met:
   - "Stay Healthy": "HealthLow" = true (not achieved) âœ… Include
   - "Wander": "AgentMoving" = false (not achieved) âœ… Include

3. Process highest priority: "Stay Healthy"
```

**Phase 2: Backward Chaining (Graph Search)**

```
Node 0 (Root): "Stay Healthy" Goal
â”œâ”€â”€ Required Effects: {"HealthLow" = false}
â”œâ”€â”€ Current World State: {"HealthLow" = true}
â””â”€â”€ Search for actions...

    Found: "Eat Food" â†’ Effects include "HealthLow" = false âœ…

    Node 1: After "Eat Food"
    â”œâ”€â”€ Parent: Node 0
    â”œâ”€â”€ Action: "Eat Food"
    â”œâ”€â”€ Cost: 1
    â”œâ”€â”€ Required Effects: {"HealthLow" = false} - {"HealthLow" = false} + Preconditions
    â”‚   = {} + {"AtFoodShack"}
    â”‚   = {"AtFoodShack"}  â† New subgoal!
    â””â”€â”€ Search for actions that make "AtFoodShack" true...

        Found: "Go To Food Shack" â†’ Effects include "AtFoodShack" âœ…

        Node 2: After "Go To Food Shack"
        â”œâ”€â”€ Parent: Node 1
        â”œâ”€â”€ Action: "Go To Food Shack"
        â”œâ”€â”€ Cost: 1 + 2 = 3
        â”œâ”€â”€ Required Effects: {"AtFoodShack"} - {"AtFoodShack"} + Preconditions
        â”‚   = {} + {"AgentIdle"}
        â”‚   = {"AgentIdle"}  â† New subgoal!
        â””â”€â”€ Check current world state...
            "AgentIdle" = true âœ… Already satisfied!

        Node 2 returns TRUE (path found!)
        Add Node 2 to Node 1's leaves

    Node 1 returns TRUE
    Add Node 1 to Node 0's leaves

Node 0 returns TRUE
âœ… Path found! Total cost: 3
```

**Phase 3: Extracting the Plan**

```
1. Select cheapest leaf from root:
   Node 0.Leaves = [Node 1 (cost: 3)]
   Cheapest = Node 1

2. Traverse from leaf to root, pushing actions to stack:
   Stack: []

   Navigate to Node 1: Push "Eat Food"
   Stack: [Eat Food]

   Navigate to Node 2: Push "Go To Food Shack"
   Stack: [Eat Food, Go To Food Shack]

   Node 2 has no leaves (base case)

3. Stack is now in execution order (LIFO):
   Pop â†’ "Go To Food Shack" (executes first)
   Pop â†’ "Eat Food" (executes second)
```

**Phase 4: Execution**

```
Frame 100:
â”œâ”€â”€ currentAction = null
â”œâ”€â”€ CalculatePlan() â†’ ActionPlan created
â”œâ”€â”€ Pop "Go To Food Shack" â†’ currentAction
â””â”€â”€ currentAction.Start()
    â””â”€â”€ NavigateStrategy.Start() â†’ agent.SetDestination(foodShack)

Frames 101-250:
â”œâ”€â”€ currentAction.Update(deltaTime)
â”‚   â””â”€â”€ NavigateStrategy.Update(deltaTime)
â”‚       â””â”€â”€ Check agent.remainingDistance
â”œâ”€â”€ animations.SetSpeed(agent.velocity.magnitude)  [Shows walking]
â””â”€â”€ Complete = false (still traveling)

Frame 251:
â”œâ”€â”€ currentAction.Update(deltaTime)
â”‚   â””â”€â”€ strategy.Complete = true (arrived!)
â”œâ”€â”€ currentAction.Stop()
â”œâ”€â”€ Apply Effects: "AtFoodShack" = true, "AgentMoving" = true
â”œâ”€â”€ actionPlan.Actions.Count = 1 (still has "Eat Food")
â”œâ”€â”€ currentAction = null (ready for next action)

Frame 252:
â”œâ”€â”€ currentAction = null
â”œâ”€â”€ No CalculatePlan() because actionPlan exists
â”œâ”€â”€ Pop "Eat Food" â†’ currentAction
â””â”€â”€ currentAction.Start()
    â””â”€â”€ IdleStrategy.Start() â†’ timer.Start(3f)

Frames 253-433:
â”œâ”€â”€ currentAction.Update(deltaTime)
â”‚   â””â”€â”€ IdleStrategy.Update(deltaTime)
â”‚       â””â”€â”€ timer.Tick(deltaTime)
â”œâ”€â”€ animations.SetSpeed(0)  [Shows idle]
â””â”€â”€ Complete = false (timer running)

Frame 434:
â”œâ”€â”€ currentAction.Update(deltaTime)
â”‚   â””â”€â”€ strategy.Complete = true (timer finished!)
â”œâ”€â”€ currentAction.Stop()
â”œâ”€â”€ Apply Effects: "HealthLow" = false âœ… GOAL ACHIEVED!
â”œâ”€â”€ actionPlan.Actions.Count = 0 (plan complete!)
â”œâ”€â”€ lastGoal = "Stay Healthy"
â”œâ”€â”€ currentGoal = null
â””â”€â”€ currentAction = null

Frame 435:
â”œâ”€â”€ currentAction = null
â”œâ”€â”€ CalculatePlan() â†’ Check all goals
â”‚   â”œâ”€â”€ "Stay Healthy": "HealthLow" = false âœ… Already satisfied (skipped)
â”‚   â””â”€â”€ "Wander": "AgentMoving" = false âŒ Not satisfied
â”œâ”€â”€ Plan for "Wander": [Wander Around]
â””â”€â”€ Cycle continues...
```

---

## Practical Examples & Scenarios

### ğŸ“š Scenario 1: Simple Idle Behavior

**Setup**:

```csharp
// In GoapAgent SetupBeliefs():
factory.AddBelief("Nothing", () => false);  // Always false

// In SetupActions():
actions.Add(new AgentAction.Builder("Relax")
    .WithStrategy(new IdleStrategy(5))
    .AddEffect(beliefs["Nothing"])
    .Build());

// In SetupGoals():
goals.Add(new AgentGoal.Builder("Chill Out")
    .WithPriority(1)
    .WithDesiredEffects(beliefs["Nothing"])
    .Build());
```

**What Happens**:

1. Goal "Chill Out" wants "Nothing" = true
2. "Nothing" is ALWAYS false (so goal is never truly achieved)
3. Planner finds "Relax" action (effect is "Nothing")
4. Agent executes "Relax" â†’ Idles for 5 seconds
5. After 5 seconds, "Nothing" is still false
6. Planner creates new plan â†’ "Relax" again
7. **Result**: Agent perpetually idles (fallback behavior)

**Why This Design?**

- Ensures agent ALWAYS has something to do
- Prevents null plans when no meaningful goals are achievable
- Acts as a "default" state

---

### ğŸ“š Scenario 2: Health/Stamina Management

Let's extend the system to handle survival:

```csharp
// BELIEFS
factory.AddBelief("HealthLow", () => health < 30);
factory.AddBelief("StaminaLow", () => stamina < 30);
factory.AddLocationBelief("AtFoodShack", 3f, foodShack);
factory.AddLocationBelief("AtRest", 3f, restingPosition);

// ACTIONS
actions.Add(new AgentAction.Builder("Go To Food")
    .WithCost(2)
    .WithStrategy(new NavigateStrategy(navMeshAgent, foodShack.position))
    .AddPrecondition(beliefs["AgentIdle"])
    .AddEffect(beliefs["AtFoodShack"])
    .Build());

actions.Add(new AgentAction.Builder("Eat")
    .WithCost(1)
    .WithStrategy(new IdleStrategy(3))
    .AddPrecondition(beliefs["AtFoodShack"])
    .AddEffect(beliefs["HealthLow"])  // Makes it FALSE when evaluated
    .Build());

actions.Add(new AgentAction.Builder("Go To Bed")
    .WithCost(2)
    .WithStrategy(new NavigateStrategy(navMeshAgent, restingPosition.position))
    .AddPrecondition(beliefs["AgentIdle"])
    .AddEffect(beliefs["AtRest"])
    .Build());

actions.Add(new AgentAction.Builder("Sleep")
    .WithCost(1)
    .WithStrategy(new IdleStrategy(5))
    .AddPrecondition(beliefs["AtRest"])
    .AddEffect(beliefs["StaminaLow"])
    .Build());

// GOALS
goals.Add(new AgentGoal.Builder("Stay Healthy")
    .WithPriority(10)
    .WithDesiredEffects(beliefs["HealthLow"])  // Want this to be FALSE
    .Build());

goals.Add(new AgentGoal.Builder("Stay Energized")
    .WithPriority(8)
    .WithDesiredEffects(beliefs["StaminaLow"])
    .Build());
```

**Emergent Behavior**:

```
CASE A: Health = 20, Stamina = 100, At random location
â†’ Goal: "Stay Healthy" (priority 10)
â†’ Plan: [Go To Food, Eat]
â†’ Agent walks to food shack and eats

CASE B: Health = 100, Stamina = 20, At random location
â†’ Goal: "Stay Energized" (priority 8)
â†’ Plan: [Go To Bed, Sleep]
â†’ Agent walks to bed and sleeps

CASE C: Health = 20, Stamina = 20, At random location
â†’ Goal: "Stay Healthy" (priority 10 > 8)
â†’ Plan: [Go To Food, Eat]
â†’ After eating, health is restored
â†’ Next frame: Goal "Stay Energized" becomes highest priority
â†’ Plan: [Go To Bed, Sleep]
â†’ Agent then goes to sleep

CASE D: Health = 25, standing AT food shack
â†’ Goal: "Stay Healthy"
â†’ Belief "AtFoodShack" = true (already there!)
â†’ Plan: [Eat]  â† Skips navigation!
â†’ More efficient planning
```

---

### ğŸ“š Scenario 3: Combat with Tactical Retreat

```csharp
// BELIEFS
factory.AddSensorBelief("EnemyNearby", attackSensor);  // Adds location
factory.AddBelief("HasWeapon", () => currentWeapon != null);
factory.AddBelief("HealthLow", () => health < 30);
factory.AddLocationBelief("AtCover", 2f, coverPosition);

// ACTIONS
actions.Add(new AgentAction.Builder("Pick Up Weapon")
    .WithCost(2)
    .WithStrategy(new NavigateToItemStrategy(navMeshAgent, "Weapon"))
    .AddEffect(beliefs["HasWeapon"])
    .Build());

actions.Add(new AgentAction.Builder("Shoot Enemy")
    .WithCost(1)
    .WithStrategy(new AttackStrategy(attackSensor, animations))
    .AddPrecondition(beliefs["EnemyNearby"])
    .AddPrecondition(beliefs["HasWeapon"])
    .AddEffect(beliefs["EnemyNearby"])  // Makes FALSE (enemy dead)
    .Build());

actions.Add(new AgentAction.Builder("Take Cover")
    .WithCost(3)
    .WithStrategy(new NavigateStrategy(navMeshAgent, coverPosition.position))
    .AddPrecondition(beliefs["HealthLow"])
    .AddEffect(beliefs["AtCover"])
    .Build());

actions.Add(new AgentAction.Builder("Heal")
    .WithCost(1)
    .WithStrategy(new IdleStrategy(5))
    .AddPrecondition(beliefs["AtCover"])
    .AddEffect(beliefs["HealthLow"])
    .Build());

// GOALS
goals.Add(new AgentGoal.Builder("Survive")
    .WithPriority(10)
    .WithDesiredEffects(beliefs["HealthLow"])
    .Build());

goals.Add(new AgentGoal.Builder("Eliminate Threat")
    .WithPriority(8)
    .WithDesiredEffects(beliefs["EnemyNearby"])
    .Build());
```

**Intelligent Behavior**:

```
SCENARIO A: Healthy + Enemy Nearby + Has Weapon
â†’ Goal: "Eliminate Threat" (priority 8)
â†’ Plan: [Shoot Enemy]
â†’ Agent immediately attacks

SCENARIO B: Healthy + Enemy Nearby + NO Weapon
â†’ Goal: "Eliminate Threat"
â†’ Plan: [Pick Up Weapon, Shoot Enemy]
â†’ Agent fetches weapon first, then attacks

SCENARIO C: Low Health + Enemy Nearby + Has Weapon
â†’ Goal: "Survive" (priority 10 > 8)
â†’ Plan: [Take Cover, Heal]
â†’ Agent RETREATS instead of fighting!
â†’ After healing, health restored
â†’ Next frame: Goal "Eliminate Threat" becomes top priority
â†’ Plan: [Shoot Enemy]
â†’ Agent re-engages

SCENARIO D: Low Health + Enemy Nearby + NO Weapon
â†’ Goal: "Survive" (priority 10)
â†’ Plan: [Take Cover, Heal]
â†’ Agent retreats first (doesn't try to get weapon while hurt)
â†’ After healing: Plan: [Pick Up Weapon, Shoot Enemy]
```

**This demonstrates**:

- âœ… **Self-preservation** (retreats when hurt)
- âœ… **Tactical thinking** (gets weapon before fighting)
- âœ… **Priority-based decision making** (survival > combat)
- âœ… **Emergent behavior** (you didn't code "retreat when hurt without weapon" - it emerged!)

---

### ğŸ“š Scenario 4: Sensor-Driven Replanning

**What Happens When Player Enters/Exits Range?**

```csharp
// Initial situation:
Health: 100, No enemy nearby, At random location
Current Goal: "Wander" (low priority)
Current Plan: [Wander Around]
Current Action: Executing WanderStrategy (walking to random point)

// â±ï¸ 2 seconds later...
Player walks into attackSensor range!

Sensor.OnTriggerEnter(player):
â”œâ”€â”€ UpdateTargetPosition(player.gameObject)
â”œâ”€â”€ target = player
â”œâ”€â”€ lastKnownPosition = player.position
â””â”€â”€ OnTargetChanged.Invoke()  â† EVENT FIRED

GoapAgent.HandleTargetChanged():
â”œâ”€â”€ Debug.Log("Target changed, clearing action and goal")
â”œâ”€â”€ currentAction = null  â† INTERRUPTS wandering
â””â”€â”€ currentGoal = null    â† FORCES replanning

// Next frame:
GoapAgent.Update():
â”œâ”€â”€ currentAction == null âœ…
â”œâ”€â”€ CalculatePlan()
â”‚   â”œâ”€â”€ beliefs["EnemyNearby"].Evaluate() = true (sensor has target)
â”‚   â”œâ”€â”€ Goal "Eliminate Threat" now has unmet desired effect
â”‚   â””â”€â”€ Plan: [Pick Up Weapon, Shoot Enemy]
â”œâ”€â”€ currentAction = "Pick Up Weapon"
â””â”€â”€ navMeshAgent.SetDestination(weaponLocation)

Result: Agent IMMEDIATELY stops wandering and goes into combat mode!
```

**Exit Behavior**:

```csharp
Player runs away, exits sensor range

Sensor.OnTriggerExit(player):
â”œâ”€â”€ UpdateTargetPosition(null)  â† No target
â”œâ”€â”€ target = null
â””â”€â”€ OnTargetChanged.Invoke()  â† EVENT FIRED

GoapAgent.HandleTargetChanged():
â”œâ”€â”€ currentAction = null  â† Stops shooting
â””â”€â”€ currentGoal = null

// Next frame:
beliefs["EnemyNearby"].Evaluate() = false  â† Sensor has no target
Goal "Eliminate Threat" now satisfied (desired: not nearby)
New plan for "Wander" goal
Agent resumes patrol
```

---

## Code Flow Diagrams

### ğŸ”„ **Initialization Flow**

```
Unity Awake():
    GoapAgent.Awake()
    â”œâ”€â”€ navMeshAgent = GetComponent<NavMeshAgent>()
    â”œâ”€â”€ animations = GetComponent<AnimationController>()
    â”œâ”€â”€ rb = GetComponent<Rigidbody>()
    â”‚   â””â”€â”€ rb.freezeRotation = true
    â””â”€â”€ gPlanner = new GoapPlanner()

Unity Start():
    GoapAgent.Start()
    â”œâ”€â”€ SetupTimers()
    â”‚   â”œâ”€â”€ statsTimer = new CountdownTimer(2f)
    â”‚   â”œâ”€â”€ statsTimer.OnTimerStop += UpdateStats + Restart
    â”‚   â””â”€â”€ statsTimer.Start()
    â”‚
    â”œâ”€â”€ SetupBeliefs()
    â”‚   â”œâ”€â”€ beliefs = new Dictionary<string, AgentBelief>()
    â”‚   â”œâ”€â”€ factory = new BeliefFactory(this, beliefs)
    â”‚   â”œâ”€â”€ factory.AddBelief("Nothing", () => false)
    â”‚   â”œâ”€â”€ factory.AddBelief("AgentIdle", () => !navMeshAgent.hasPath)
    â”‚   â””â”€â”€ factory.AddBelief("AgentMoving", () => navMeshAgent.hasPath)
    â”‚
    â”œâ”€â”€ SetupActions()
    â”‚   â”œâ”€â”€ actions = new HashSet<AgentAction>()
    â”‚   â”œâ”€â”€ actions.Add("Relax" action)
    â”‚   â””â”€â”€ actions.Add("Wander Around" action)
    â”‚
    â””â”€â”€ SetupGoals()
        â”œâ”€â”€ goals = new HashSet<AgentGoal>()
        â”œâ”€â”€ goals.Add("Chill Out" goal)
        â””â”€â”€ goals.Add("Wander" goal)

Unity OnEnable():
    chaseSensor.OnTargetChanged += HandleTargetChanged
```

---

### ğŸ”„ **Planning Flow (Detailed)**

```
CalculatePlan()
â”‚
â”œâ”€ Determine priority level
â”‚  â””â”€ priorityLevel = currentGoal?.Priority ?? 0
â”‚
â”œâ”€ Determine which goals to check
â”‚  â”œâ”€ IF currentGoal exists:
â”‚  â”‚  â””â”€ goalsToCheck = goals where (g.Priority > priorityLevel)
â”‚  â””â”€ ELSE:
â”‚     â””â”€ goalsToCheck = all goals
â”‚
â””â”€ Call GoapPlanner.Plan(this, goalsToCheck, lastGoal)
   â”‚
   â”œâ”€ GoapPlanner.Plan()
   â”‚  â”‚
   â”‚  â”œâ”€ Filter goals
   â”‚  â”‚  â””â”€ orderedGoals = goals where (any DesiredEffect.Evaluate() == false)
   â”‚  â”‚     .OrderByDescending(priority with mostRecentGoal penalty)
   â”‚  â”‚
   â”‚  â”œâ”€ FOR EACH goal in orderedGoals:
   â”‚  â”‚  â”‚
   â”‚  â”‚  â”œâ”€ Create root node
   â”‚  â”‚  â”‚  â””â”€ goalNode = new Node(null, null, goal.DesiredEffects, 0)
   â”‚  â”‚  â”‚
   â”‚  â”‚  â”œâ”€ FindPath(goalNode, agent.actions)
   â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”œâ”€ FOR EACH action in actions:
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ Copy required effects
   â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ requiredEffects = parent.RequiredEffects.Clone()
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ Remove satisfied effects
   â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ requiredEffects.RemoveWhere(b => b.Evaluate())
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ IF requiredEffects.Count == 0:
   â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ return true  â† BASE CASE (all satisfied)
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ IF action.Effects overlap with requiredEffects:
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ Calculate new required effects
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ newRequired = requiredEffects - action.Effects
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ newRequired += action.Preconditions
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ Create child node
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ newNode = new Node(parent, action, newRequired, parent.Cost + action.Cost)
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ Recurse
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ IF FindPath(newNode, actions - currentAction):
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚     â””â”€ parent.Leaves.Add(newNode)
   â”‚  â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ IF newRequired.Count == 0:
   â”‚  â”‚  â”‚  â”‚  â”‚     â””â”€ return true
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â””â”€ (continue to next action)
   â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â””â”€ return false  â† No path found
   â”‚  â”‚  â”‚
   â”‚  â”‚  â”œâ”€ IF FindPath succeeded AND goalNode.Leaves.Count > 0:
   â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”œâ”€ Build action stack by traversing tree
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ actionStack = new Stack<AgentAction>()
   â”‚  â”‚  â”‚  â”‚  â”œâ”€ currentNode = goalNode
   â”‚  â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â”‚  â””â”€ WHILE currentNode.Leaves.Count > 0:
   â”‚  â”‚  â”‚  â”‚     â”œâ”€ cheapestLeaf = currentNode.Leaves.OrderBy(cost).First()
   â”‚  â”‚  â”‚  â”‚     â”œâ”€ currentNode = cheapestLeaf
   â”‚  â”‚  â”‚  â”‚     â””â”€ actionStack.Push(cheapestLeaf.Action)
   â”‚  â”‚  â”‚  â”‚
   â”‚  â”‚  â”‚  â””â”€ RETURN new ActionPlan(goal, actionStack, cost)
   â”‚  â”‚  â”‚
   â”‚  â”‚  â””â”€ (try next goal)
   â”‚  â”‚
   â”‚  â””â”€ RETURN null  â† No goals had valid plans
   â”‚
   â””â”€ IF potentialPlan != null:
      â”œâ”€ actionPlan = potentialPlan
      â””â”€ (Update GoapAgent's actionPlan)
```

---

### ğŸ”„ **Action Execution Flow**

```
Frame N (currentAction == null):
â”‚
â”œâ”€ CalculatePlan()  [See above]
â”‚  â””â”€ actionPlan created: Stack = [Action2, Action1]
â”‚
â”œâ”€ currentGoal = actionPlan.AgentGoal
â”œâ”€ currentAction = actionPlan.Actions.Pop()  â†’ Action1
â”œâ”€ currentAction.Start()
â”‚  â””â”€ strategy.Start()
â”‚     â””â”€ (Initialize execution, e.g., set nav destination)
â”‚
â””â”€ Debug: "Goal: {goal} with {count} actions in plan"

Frame N+1 to N+M (action executing):
â”‚
â”œâ”€ currentAction != null âœ…
â”œâ”€ currentAction.Update(Time.deltaTime)
â”‚  â”‚
â”‚  â”œâ”€ IF strategy.CanPerform:
â”‚  â”‚  â””â”€ strategy.Update(deltaTime)
â”‚  â”‚     â””â”€ (Execute action logic, e.g., navigate, wait timer)
â”‚  â”‚
â”‚  â”œâ”€ IF !strategy.Complete:
â”‚  â”‚  â””â”€ return  â† Still executing
â”‚  â”‚
â”‚  â””â”€ IF strategy.Complete:
â”‚     â””â”€ FOR EACH effect in Effects:
â”‚        â””â”€ effect.Evaluate()  â† Updates world state
â”‚
â””â”€ Complete = false (not done yet)

Frame N+M+1 (action completes):
â”‚
â”œâ”€ currentAction.Update(deltaTime)
â”‚  â””â”€ strategy.Complete = true âœ…
â”‚
â”œâ”€ currentAction.Complete = true
â”œâ”€ currentAction.Stop()
â”‚  â””â”€ strategy.Stop()
â”‚     â””â”€ (Cleanup)
â”‚
â”œâ”€ Debug: "{actionName} complete"
â”‚
â”œâ”€ IF actionPlan.Actions.Count == 0:
â”‚  â”œâ”€ Debug: "Plan complete"
â”‚  â”œâ”€ lastGoal = currentGoal
â”‚  â”œâ”€ currentGoal = null
â”‚  â””â”€ currentAction = null
â”‚
â””â”€ ELSE:
   â””â”€ currentAction = null  â† Will pop next action next frame
```

---

## Extending the System

### ğŸ”§ Adding a New Action

**Example**: Add a "door opening" action

```csharp
// Step 1: Add belief for door state
factory.AddBelief("DoorOpen", () => door.isOpen);
factory.AddLocationBelief("AtDoor", 2f, doorPosition);

// Step 2: Create action
actions.Add(new AgentAction.Builder("Open Door")
    .WithCost(1)
    .WithStrategy(new InteractStrategy(door.gameObject, "Open"))
    .AddPrecondition(beliefs["AtDoor"])
    .AddEffect(beliefs["DoorOpen"])
    .Build());

// Step 3: Create strategy (if custom behavior needed)
public class InteractStrategy : IActionStrategy {
    GameObject target;
    string interactionName;

    public bool CanPerform => target != null;
    public bool Complete { get; private set; }

    public InteractStrategy(GameObject target, string interaction) {
        this.target = target;
        interactionName = interaction;
    }

    public void Start() {
        // Send message to target object
        target.SendMessage(interactionName);
        Complete = true;  // Instant interaction
    }
}
```

**That's it!** The planner automatically incorporates "Open Door" into plans:

- If goal requires being past door â†’ Plans: [Go To Door, Open Door, ...]
- If door is already open â†’ Skips opening action

---

### ğŸ”§ Adding a New Goal

```csharp
// Step 1: Define belief for goal condition
factory.AddLocationBelief("AtDestination", 1f, targetLocation);

// Step 2: Create goal
goals.Add(new AgentGoal.Builder("Reach Destination")
    .WithPriority(5)
    .WithDesiredEffects(beliefs["AtDestination"])
    .Build());
```

**Automatic Integration**:

- Planner checks if "AtDestination" is false
- Looks for actions with "AtDestination" effect
- Builds plan using existing navigation actions

---

### ğŸ”§ Adding Complex Multi-Step Actions

**Example**: Crafting system

```csharp
// Beliefs
factory.AddBelief("HasWood", () => inventory.HasItem("Wood"));
factory.AddBelief("HasStone", () => inventory.HasItem("Stone"));
factory.AddBelief("HasAxe", () => inventory.HasItem("Axe"));
factory.AddLocationBelief("AtWorkbench", 2f, workbench);

// Actions
actions.Add(new AgentAction.Builder("Gather Wood")
    .WithCost(3)
    .WithStrategy(new GatherResourceStrategy("Wood"))
    .AddEffect(beliefs["HasWood"])
    .Build());

actions.Add(new AgentAction.Builder("Gather Stone")
    .WithCost(3)
    .WithStrategy(new GatherResourceStrategy("Stone"))
    .AddEffect(beliefs["HasStone"])
    .Build());

actions.Add(new AgentAction.Builder("Craft Axe")
    .WithCost(2)
    .WithStrategy(new CraftingStrategy("Axe"))
    .AddPrecondition(beliefs["HasWood"])
    .AddPrecondition(beliefs["HasStone"])
    .AddPrecondition(beliefs["AtWorkbench"])
    .AddEffect(beliefs["HasAxe"])
    .Build());

// Goal
goals.Add(new AgentGoal.Builder("Get Axe")
    .WithPriority(7)
    .WithDesiredEffects(beliefs["HasAxe"])
    .Build());
```

**Emergent Plan**:

```
CASE: No wood, no stone, not at workbench
â†’ Plan: [Gather Wood, Gather Stone, Go To Workbench, Craft Axe]

CASE: Has wood, no stone, not at workbench
â†’ Plan: [Gather Stone, Go To Workbench, Craft Axe]

CASE: Has wood, has stone, not at workbench
â†’ Plan: [Go To Workbench, Craft Axe]

CASE: Has wood, has stone, AT workbench
â†’ Plan: [Craft Axe]
```

The planner automatically optimizes based on current state!

---

### ğŸ”§ Advanced: Adding Action Costs for Smart Behavior

```csharp
// Expensive but safe route
actions.Add(new AgentAction.Builder("Take Safe Path")
    .WithCost(10)  // High cost
    .WithStrategy(new NavigateStrategy(navMeshAgent, safePath))
    .AddEffect(beliefs["AtDestination"])
    .Build());

// Cheap but dangerous route
actions.Add(new AgentAction.Builder("Take Shortcut")
    .WithCost(2)  // Low cost
    .WithStrategy(new NavigateStrategy(navMeshAgent, dangerousPath))
    .AddPrecondition(beliefs["HealthHigh"])  // Only if healthy
    .AddEffect(beliefs["AtDestination"])
    .Build());
```

**Behavior**:

- High health â†’ Takes shortcut (cheaper)
- Low health â†’ Takes safe path (even though more expensive)
- Beliefs gate risky actions!

---

## Summary & Key Takeaways

### ğŸ¯ Core Concepts

1. **Beliefs** = What the agent knows (world state)
2. **Actions** = What the agent can do (with preconditions & effects)
3. **Goals** = What the agent wants (desired world state)
4. **Planner** = How the agent thinks (backward-chaining graph search)
5. **Strategies** = How actions are executed (navigation, timing, etc.)

### ğŸ§  How GOAP Differs from FSMs

| Aspect                | Finite State Machine   | GOAP                     |
| --------------------- | ---------------------- | ------------------------ |
| **Transitions**       | Manually defined       | Automatically discovered |
| **Scalability**       | Exponential complexity | Linear addition          |
| **Flexibility**       | Rigid                  | Dynamic replanning       |
| **Design**            | State-centric          | Goal-centric             |
| **Emergent Behavior** | Rare                   | Common                   |

### âœ… Best Practices

1. **Keep actions atomic** - One action = one clear purpose
2. **Use meaningful costs** - Reflect actual effort/danger/time
3. **Define clear preconditions** - Prevents impossible plans
4. **Test beliefs frequently** - Stale data = bad plans
5. **Use priority wisely** - High priority = interrupts current plans
6. **Leverage sensors** - Dynamic world state updates
7. **Log everything (debug builds)** - GOAP can be hard to debug without logs

### âš ï¸ Common Pitfalls

1. **Circular dependencies** - Action A needs B, B needs A â†’ No plan found
2. **Always-true preconditions** - Makes actions too permissive
3. **Always-false effects** - Creates unsolvable goals
4. **Too many actions** - Planning becomes slow (use profiler!)
5. **Forgetting to update beliefs** - Agent acts on old information

---

## Resources & References

- **Original GOAP Paper**: Jeff Orkin (F.E.A.R. AI) - "Three States and a Plan: The A.I. of F.E.A.R."
- **Unity NavMesh Documentation**: [docs.unity3d.com/Manual/Navigation.html](https://docs.unity3d.com/Manual/Navigation.html)
- **A\* Algorithm**: [wikipedia.org/wiki/A\*\_search_algorithm](https://en.wikipedia.org/wiki/A*_search_algorithm)
- **Builder Pattern**: [refactoring.guru/design-patterns/builder](https://refactoring.guru/design-patterns/builder)

---

## Conclusion

This GOAP system provides a robust foundation for intelligent AI agents. The beauty of GOAP is that **complex behaviors emerge from simple rules**. As you add more beliefs, actions, and goals, the agents become more "alive" without requiring exponentially more code.

**Next Steps**:

1. Run the current implementation and observe wandering behavior
2. Add health/stamina actions as shown in examples
3. Implement combat with sensors
4. Create NPC-specific goals (guard posts, patrols, etc.)
5. Profile performance and optimize planning if needed

The system is designed to grow with your game!
